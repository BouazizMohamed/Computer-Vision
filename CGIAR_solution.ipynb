{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction:\n",
        "The \"Eyes on the Ground'' project is a collaboration between ACRE Africa, the International Food Policy Research Institute (IFPRI), and the Lacuna Fund, to create a large machine learning (ML) dataset that provides a close-up view of smallholder farmer's fields based upon previous work within the Picture Based Insurance framework.\n",
        "\n",
        "In order to help farmers across Africa manage agricultural risk, ACRE Africa utilizes image data to settle insurance claims and carry out loss assessment. ACRE reviews smartphone pictures of insured crops sent in by farmers to verify whether a farmerâ€™s crops werelooking at damaged,s and whether this damage was related to weather, pests and diseases, oras well as man-made factors such as fire, to evaluate an insurance claim and determine appropriate compensation.\n",
        "\n",
        "Evaluating images for thousands of insured smallholder farmers to verify insurance claims is however time-consuming, and this often slows down claims settlement. ACRE Africa is therefore looking at artificial intelligence to automate claims settlement, building on the training data that ACRE Africa and IFPRI produced with support from the Lacuna Fund.\n",
        "\n",
        "Since most claims are related to drought, this challenge will ask participants to predict drought damage from smartphone images of crops taken in the past. The Eyes-on-the-Ground project has already successfully trained models to predict drought damage in the first two seasons, but those models did not transfer well into the third season on which data are available.(https://zindi.africa/competitions/cgiar-eyes-on-the-ground-challenge)"
      ],
      "metadata": {
        "id": "F3LCSUfZ_HTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "guLSnVNS_HjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqPeL5QftaW4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers.schedules import InverseTimeDecay\n",
        "from sklearn.model_selection import KFold\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models , layers\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "eJk7PvS9ApoC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tf4egHbtu8y"
      },
      "outputs": [],
      "source": [
        "local_zip = '/content/drive/MyDrive/Data/test.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/test')\n",
        "zip_ref.close()\n",
        "local_zip = '/content/drive/MyDrive/Data/train.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/train')\n",
        "zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGFN44QbuN1g",
        "outputId": "30732950-941c-45cf-fa02-282ec7dde1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 26068 train images.\n",
            "There are 8663 test images .\n"
          ]
        }
      ],
      "source": [
        "source_path_train = '/content/train'\n",
        "source_path_test = '/content/test'\n",
        "print(f\"There are {len(os.listdir(source_path_train))} train images.\")\n",
        "print(f\"There are {len(os.listdir(source_path_test))} test images .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrEruE5OI3iP"
      },
      "outputs": [],
      "source": [
        "test=pd.read_csv(\"/content/Test.csv\")\n",
        "train=pd.read_csv(\"/content/Train.csv\")\n",
        "trainDR = train[train[\"extent\"] !=0].dropna()\n",
        "trainDR=trainDR.drop(\"damage\",axis=1)\n",
        "testDR = test[test[\"damage\"] == 'DR']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "c1TpNVXOAziE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQoMuscQM3fa"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 128\n",
        "INPUT_SHAPE = [None, 224, 224, 3]\n",
        "feature=[None,8]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path):\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image,3)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
        "  return image\n",
        "def process_image1(image):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
        "  return image\n",
        "def get_image_label1(image,data):\n",
        "  image = process_image1(image)\n",
        "  return (image,data),\n",
        "def get_image_label2(image,data):\n",
        "  image = process_image(image)\n",
        "  return (image,data),\n",
        "def get_image_label(data,label=None):\n",
        "  image = process_image(data[0])\n",
        "  return ((image,data[1]),label)"
      ],
      "metadata": {
        "id": "G9gN9JQG9N__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmC_ROo5zXbf"
      },
      "outputs": [],
      "source": [
        "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  if test_data:\n",
        "    data = tf.data.Dataset.from_tensor_slices((y,tf.constant(x)))\n",
        "    data = data.map(get_image_label1)\n",
        "    return data.batch(BATCH_SIZE)\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    train2=pd.get_dummies(x[['growth_stage','season']])\n",
        "    data = tf.data.Dataset.from_tensor_slices(((tf.constant(x['filename']),tf.constant(train2)),tf.constant(y)))\n",
        "    data = data.map(get_image_label)\n",
        "    return data.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    train2=pd.get_dummies(x[['growth_stage','season']])\n",
        "    data = tf.data.Dataset.from_tensor_slices(((tf.constant(x['filename']),tf.constant(train2)),tf.constant(y)))\n",
        "    data = data.map(get_image_label)\n",
        "    return data.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_batches_test(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    train2=pd.get_dummies(x[['growth_stage','season']])\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x['filename']),tf.constant(train2)))\n",
        "    data = data.map(get_image_label2)\n",
        "    return data.batch(BATCH_SIZE)\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    train2=pd.get_dummies(x[['growth_stage','season']])\n",
        "    data = tf.data.Dataset.from_tensor_slices(((tf.constant(x['filename']),tf.constant(train2)),tf.constant(y)))\n",
        "    data = data.map(get_image_label)\n",
        "    return data.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    train2=pd.get_dummies(x[['growth_stage','season']])\n",
        "    data = tf.data.Dataset.from_tensor_slices(((tf.constant(x['filename']),tf.constant(train2)),tf.constant(y)))\n",
        "    data = data.map(get_image_label)\n",
        "    return data.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "8n6xkXvaVxAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t90JiWFEyvFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7b5251-4820-4454-9a9b-92d87a6048f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d55d7a09dbab>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train1['filename'][i]='train/' + train1.iloc[i,1]\n"
          ]
        }
      ],
      "source": [
        "train1=trainDR.sample(frac=1,random_state=42).reset_index(drop=True)\n",
        "for i in range(4510):\n",
        "  train1['filename'][i]='train/' + train1.iloc[i,1]\n",
        "X=train1.drop(\"extent\",axis=1)\n",
        "y=train1[\"extent\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "5K1iVKlnA1-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xth8Kh7ysg7D"
      },
      "outputs": [],
      "source": [
        "#MODEL_URL = \"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\"\n",
        "#MODEL_URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "#MODEL_URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2\"\n",
        "MODEL_URL = \"https://tfhub.dev/sayakpaul/swin_base_patch4_window7_224_fe/1\"\n",
        "#MODEL_URL =\"https://tfhub.dev/sayakpaul/convnext_xlarge_21k_224/1\"\n",
        "#MODEL_URL = \"https://tfhub.dev/sayakpaul/swin_base_patch4_window12_384/1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoocMCe76Sb9"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.001\n",
        "decay_steps = 1000\n",
        "decay_rate = 0.5\n",
        "def create_model(input_shape=INPUT_SHAPE, model_url=MODEL_URL):\n",
        "    print(\"Building model with:\", MODEL_URL)\n",
        "    x_input = tf.keras.Input(shape=(224,224,3))\n",
        "    x = hub.KerasLayer(MODEL_URL)(x_input)\n",
        "    x1_input = tf.keras.Input(shape=(8,))\n",
        "    x1 = tf.keras.layers.Dense(512, activation='relu')(x1_input)\n",
        "    x1 = tf.keras.layers.Dense(512, activation='relu')(x1)\n",
        "    combined0 = tf.keras.layers.concatenate([x,x1])\n",
        "    combined = tf.keras.layers.Dense(512, activation='relu')(combined0)\n",
        "    combined = tf.keras.layers.Dense(512, activation='relu')(combined)\n",
        "    y1_output = tf.keras.layers.Dense(1, name='y1_output')(combined)\n",
        "    lr_schedule = InverseTimeDecay(initial_learning_rate, decay_steps, decay_rate)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    model = tf.keras.Model(inputs=[x_input, x1_input],outputs=[y1_output])\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss={'y1_output': 'mean_squared_error'},\n",
        "              metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError()})\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error', patience=5, restore_best_weights=True,mode='min')\n",
        "class DetectOverfittingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold=2):\n",
        "        super(DetectOverfittingCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs[\"val_root_mean_squared_error\"]\n",
        "        train_loss = logs[\"root_mean_squared_error\"]\n",
        "        if val_loss < self.best_val_loss:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        ratio = val_loss - train_loss\n",
        "        print(\"Epoch: {}, Val-Train: {:.2f}\".format(epoch, ratio))\n",
        "        if ratio > self.threshold:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n",
        "    def get_best_weights(self):\n",
        "        return self.best_weights"
      ],
      "metadata": {
        "id": "vPCt5dd41bbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 3\n",
        "NUM_EPOCHS = 30\n",
        "def cross_validation():\n",
        "  kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "  fold_results = []\n",
        "  for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "      print(f\"Training fold {fold+1}/{num_folds}\")\n",
        "      X_fold_train, X_fold_val = X.iloc[train_index], X.iloc[val_index]\n",
        "      y_fold_train, y_fold_val = y.iloc[train_index], y.iloc[val_index]\n",
        "      train_data = create_data_batches(X_fold_train, y_fold_train)\n",
        "      val_data = create_data_batches(X_fold_val, y_fold_val, valid_data=True)\n",
        "      model = create_model()\n",
        "      history=model.fit(train_data,\n",
        "                  epochs=NUM_EPOCHS,\n",
        "                  validation_data=val_data,\n",
        "                  validation_freq=1,\n",
        "                  shuffle=True)\n",
        "      fold_results.append(model.evaluate(X_fold_val, verbose=0))\n",
        "  avg_loss = np.mean([result[0] for result in fold_results])\n",
        "  avg_acc = np.mean([result[1] for result in fold_results])\n",
        "  print(f\"Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_acc:.4f}\")\n",
        "  return model,history\n",
        "model,history=cross_validation()"
      ],
      "metadata": {
        "id": "abMtD719cXGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXVQTk50-a1Y"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7F3xPhbXt3c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n",
        "    plt.plot(history.history['val_root_mean_squared_error'], label='val_root_mean_squared_error')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metric')\n",
        "    plt.title('Training and Validation Metric')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "auuLjK60B6sf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g64AW_0B0S3-"
      },
      "outputs": [],
      "source": [
        "test1=testDR.reset_index(drop=True)\n",
        "for i in range(1503):\n",
        "  test1['filename'][i]='test/' + test1.iloc[i,1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_augmentation(pas,pas1):\n",
        "  test2=pd.get_dummies(test1[['growth_stage','season']])\n",
        "  pred=[]\n",
        "  for i in range(1503):\n",
        "    print(i)\n",
        "    predictions1 = []\n",
        "    crop_locations = []\n",
        "    image = tf.io.read_file(test1[\"filename\"][i])\n",
        "    image = tf.image.decode_jpeg(image,3)\n",
        "    a=image.shape[0]\n",
        "    b=image.shape[1]\n",
        "    p=pas\n",
        "    c=int(image.shape[0]/p)*pas1\n",
        "    d=int(image.shape[1]/p)*pas1\n",
        "    crop_size = (a-pas1*c,b-pas1*d)\n",
        "    stride1 =int(image.shape[0]/p)\n",
        "    stride2 =int(image.shape[1]/p)\n",
        "    for y in range(0,c,stride1):\n",
        "        for x in range(0, d,stride2):\n",
        "            crop = image[y:y+crop_size[0], x:x+crop_size[1]]\n",
        "            crop=create_data_batches([test2.iloc[i]],[crop],test_data=True)\n",
        "            prediction = model.predict(crop)\n",
        "            predictions1.append(prediction)\n",
        "            crop_locations.append(((x,x+crop_size[1]), (y,y+crop_size[0])))\n",
        "    aggregated_prediction = np.mean(predictions1, axis=0)\n",
        "    pred.append(aggregated_prediction)\n",
        "  return pred"
      ],
      "metadata": {
        "id": "ZKM08fqK9if6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=test_augmentation(10,2)\n",
        "sub=pd.read_csv(\"/content/SampleSubmission.csv\")\n",
        "for i in range(1503):\n",
        "  indice=sub[sub[\"ID\"]==test1[\"ID\"][i]].index\n",
        "  sub.iloc[indice,1]=pred[i][0][0]\n",
        "sub.to_csv(\"/content/SampleSubmission.csv\",index=False)"
      ],
      "metadata": {
        "id": "JAeCS04GT-HS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}